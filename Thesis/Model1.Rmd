---
title: "Model"
author: "Alex Eisert"
date: "1/8/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(keras)
library(dplyr)
options(max.print=1000000)
```

```{r}
TSperPitch <- 40 ## Number of timesteps to save from the current pitch
InputLength <- 3 ## Number of variables in the input

encode <- function(Data, x){
  for (i in 1:InputLength){
    x[,,i] <- Data[,i][1:TSperPitch]
  }
  return(x)
}

encode.y <- function(Data, y){
  for (i in 1:InputLength){
    y[,,i] <- Data[,i][(TSperPitch + 1):(TSperPitch + 5)]
  }
  return(y)
}

hidden_size <- 3
Batch_size <- 1
layers <- 1

model <- keras_model_sequential()

model %>%
  layer_lstm(hidden_size, input_shape=c(TSperPitch, InputLength)) %>%
  layer_repeat_vector(5)

for(i in 1:layers){
  model %>% layer_lstm(hidden_size, return_sequences = TRUE)
}

model %>%
  time_distributed(layer_dense(units = InputLength)) %>%
  layer_activation("softmax")

model %>% compile(
  loss = "categorical_crossentropy",
  optimizer = "adam",
  metrics = "accuracy"
)

train.model <- function(Data, Model, NumPitches) {
  
Data <- data.matrix(Data)

x <- array(0, dim = c(NumPitches, TSperPitch, InputLength))
y <- array(0, dim = c(NumPitches, 5, InputLength))

x <- encode(Data, x)
y <- encode.y(Data, y)

Model %>% fit(
  x = x,
  y = y,
  batch_size = Batch_size,
  epochs = 70
)

}

summary(model)

for (i in 1:100){
  train.model(pitches[[i]], model, 1)
}

x <- array(0, dim = c(1, TSperPitch, InputLength))
new_obs <- encode((First %>% select(pos_x, pos_y, pos_z)), x)
result <- predict(model, new_obs)

result
## Does it make sense to have both training and validation when there is not independence among the observations? Validation will be more dependent on training than testing will be because validation will come right after testing

## Still confused about what "lookback" means. Also, would I even need to use "step"? Because I want to use every observation and not skip any... and how would I use delay? Because each pitch will have a different number of timesteps since it takes a different amount of time for each pitch to reach homeplate

## Can't have different input lengths in the same batch; if you want to take advantage of batch-processing, you would have to use pitches that have the same number of observations; but we don't have to work like that, and can treat each pitch as its own batch (slower, but simpler to set up; batches are really mostly to speed up processing)

## We won't be interested in predicting within ~100ms of the plate; batter has to initiate a swing by x point anyways; could truncate each pitch based on this idea

## For every pitch, we just want to use the whole pitch; no lookback or dividing into train/test/validation within each pitch... until we validate/test the model, where we'll do it on a portion of a new pitch

## Fit instead of "fit_generator"; training data instead of train_gen

## Batch is number of pitches it goes through at a time (learning algorithm computes weight adjustment as an average learning of all pitches in the batch; helps smooth out learning curve so anomalous pitches would have less of an impact... really doesn't matter the size of the batch as long as you train things enough, i.e., increase epochs? Mostly though it seems batch is for speeding things up); epochs is number of times it goes through all of the pitches

## Three axes in this array: number of pitches, length of pitches (timesteps), amount of variables per timestep (x_pos, y_pos, etc.)
## x array is input, y array is output (i.e., length of output)

## Three axes in output array: 1, 1, 3 (x pos, y pos, and time it crosses the plate)

## "batch normalization"
 
## addition_rnn

## Should we just feed x pos y pos z pos into the network and nothing else? Make at least one version like this? Should be able to infer acceleration from this

## Is it okay to feed a constant at all timesteps? Strategic info like balls & strikes? Probably fine; let's check it out

x
```

